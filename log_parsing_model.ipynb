{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jpy/anaconda3/envs/gpt/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import transformers\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_raw_bgl():\n",
    "    raw_bgl=pd.read_csv('/home/jpy/graduation_design_final/BGL/BGL_2k.log_structured.csv')\n",
    "    raw_bgl[\"Label\"]=raw_bgl[\"Label\"].apply(lambda x: int(x != \"-\"))\n",
    "    labels = raw_bgl['Label'].tolist()\n",
    "    contents = raw_bgl['Content'].to_list()\n",
    "    label_content_tuples =list(zip(labels,contents))\n",
    "\n",
    "    return label_content_tuples\n",
    "\n",
    "class TestData(Dataset):\n",
    "    def __init__(self, label_content_tuples, tokenizer, max_length=512):\n",
    "        self.data = label_content_tuples\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        labels, content, = self.data[idx]\n",
    "        \n",
    "        # 编码输入内容\n",
    "        input_text = content\n",
    "        encoding = self.tokenizer(input_text, truncation=True, padding=\"max_length\", max_length=self.max_length, return_tensors=\"pt\")\n",
    "        \n",
    "        # 编码标签\n",
    "\n",
    "        # 返回编码后的内容和标签\n",
    "        return {\n",
    "            'input_texts':input_text,\n",
    "            'input_ids': encoding['input_ids'].squeeze(0),  # 去除多余的批次维度\n",
    "            'attention_mask': encoding['attention_mask'].squeeze(0),\n",
    "            'labels':labels\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.4\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.version.cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 200/200 [00:24<00:00,  8.03batch/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "\n",
    "model_save_path = \"/home/jpy/graduation_design_final/Flan_T5_base_tuning\"\n",
    "tokenizer_save_path = \"/home/jpy/graduation_design_final/Tokenizer\"\n",
    "# 加载模型和 tokenizer\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_save_path)\n",
    "tokenizer = T5Tokenizer.from_pretrained(tokenizer_save_path)\n",
    "\n",
    "model.to('cuda')\n",
    "\n",
    "model.eval()\n",
    "\n",
    "\n",
    "test_data_tuple=load_raw_bgl()\n",
    "testdata=TestData(test_data_tuple,tokenizer=tokenizer)\n",
    "dataLoader=DataLoader(testdata,batch_size=10)\n",
    "ans_data=[]\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(dataLoader, desc=\"Processing\", unit=\"batch\"):        \n",
    "        input_texts =batch['input_texts']\n",
    "        input_ids = batch['input_ids'].to('cuda')\n",
    "        attention_mask = batch['attention_mask'].to('cuda')\n",
    "        labels= batch['labels']\n",
    "        outputs = model.generate(input_ids=input_ids,attention_mask=attention_mask,max_length=512)\n",
    "        output_texts = [tokenizer.decode(output, skip_special_tokens=True) for output in outputs]\n",
    "        for  i,output_text in enumerate(output_texts):\n",
    "            trio_tuple=(labels[i],input_texts[i],output_texts[i])\n",
    "            ans_data.append(trio_tuple)\n",
    "             \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(ans_data, columns=['Label', 'Content', 'EventTemplate'])\n",
    "# 保存为 CSV\n",
    "df.to_csv('output.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
